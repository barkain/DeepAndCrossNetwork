{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep and Cross Network\n",
    "## Pytorch implementation based on the paper arxiv.org/abs/1708.05123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch import distributions\n",
    "torch.set_num_threads(4)\n",
    "import torch.onnx\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import time\n",
    "from torchvision.transforms import *\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n",
      "number of cpu threads: 4\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using %s\"%device)\n",
    "print(\"number of cpu threads: %d\"%torch.get_num_threads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yml\", 'r') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile)\n",
    "    filename = cfg['filename']\n",
    "    x_col_cat = cfg['features']['categorical']\n",
    "    x_col_bin = cfg['features']['binary']\n",
    "    x_col_num = cfg['features']['numerical']\n",
    "    x_col_cyc = cfg['features']['cyclical']\n",
    "    y_col = cfg['features']['label']\n",
    "    w_col = cfg['features']['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: (602733, 30)\n",
      "ctr = 0.00952\n"
     ]
    }
   ],
   "source": [
    "nrows=1e7\n",
    "df = pd.read_csv(filename, nrows=nrows)\n",
    "print(\"dataset size: %s\"%str(df.shape))\n",
    "print(\"ctr = %.5f\"%((df[y_col]*df[w_col]).sum()*1./df[w_col].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_columns(arr):\n",
    "    arr = arr.astype(str)\n",
    "    vals = (arr[:,0].astype(object)+'_'+arr[:,1].astype(object))\n",
    "    for i in range(2, arr.shape[1]):\n",
    "        vals = (vals+'_'+arr[:,i].astype(object))\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['geo_state', 'geo_country', 'geo_city', 'zip_code', 'category_1', 'domain', 'app_bundle', 'publisher_id', 'device_type', 'device_os', 'device_os_version', 'device_browser', 'device_browser_version', 'carrier', 'language', 'exchange_id', 'banner_type', 'account_campaign', 'account_banner', 'account_advertiser', 'account_offer']\n"
     ]
    }
   ],
   "source": [
    "cat_features = []\n",
    "for f in x_col_cat:\n",
    "    if(isinstance(f, str)==False):\n",
    "        df[list(f.values())[0]] = df[list(f.values())[0]].fillna('unknown')\n",
    "        df[list(f.keys())[0]] = merge_columns(df[list(f.values())[0]].values)\n",
    "        cat_features.append(list(f.keys())[0])\n",
    "    else:\n",
    "        df[f] = df[f].fillna('unknown')\n",
    "        cat_features.append(f)\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df[cat_features].isnull().sum().sum()==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_interstitial {'No': 0, 'Yes': 1}\n",
      "is_mobile_web_optimized {'No': 0, 'Yes': 1}\n",
      "is_app {'Yes': 0, 'No': 1}\n",
      "['is_interstitial', 'is_mobile_web_optimized', 'is_app']\n"
     ]
    }
   ],
   "source": [
    "binary_features = []\n",
    "for f in x_col_bin:\n",
    "    uniques = df[f].unique()\n",
    "    d = {uniques[0]:0, uniques[1]:1}\n",
    "    df[f] = df[f].map(d)\n",
    "    binary_features.append(f)\n",
    "    print(f, d)\n",
    "print(binary_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_day_of_week 7\n",
      "user_hour 24\n",
      "['user_day_of_week_sin', 'user_day_of_week_cos', 'user_hour_sin', 'user_hour_cos']\n"
     ]
    }
   ],
   "source": [
    "cyc_features = []\n",
    "for f in x_col_cyc:\n",
    "    nuniques = df[f].nunique()\n",
    "    df[f+'_sin'] = np.sin(df[f]*(2.*np.pi/nuniques))\n",
    "    df[f+'_cos'] = np.cos(df[f]*(2.*np.pi/nuniques))\n",
    "    cyc_features.append(f+'_sin')\n",
    "    cyc_features.append(f+'_cos')\n",
    "    print(f, nuniques)\n",
    "print(cyc_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_encode(s, modulo, required_bits=8):\n",
    "    num = hash(s) % modulo\n",
    "    return np.array(list(np.binary_repr(num).zfill(required_bits))).astype(np.int8)\n",
    "\n",
    "def hashing_trick(s, modulo):\n",
    "    num = hash(s) % modulo\n",
    "    arr = np.zeros((modulo)).astype(np.int8)\n",
    "    arr[num] = 1\n",
    "    return arr\n",
    "\n",
    "def get_sparse_index(s, modulo):\n",
    "    return hash(s) % modulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[cat_features + binary_features + cyc_features + [y_col] + [w_col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we represent categorical features as sparse index. In production system this encoding can be done by maintaining a map of unique values per feature. A Bloom filter can be used to track each value on the fly by checking whether a specific value exists and update the counters accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:02<00:00,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo_state 642\n",
      "geo_country 13\n",
      "geo_city 5412\n",
      "zip_code 9629\n",
      "category_1 58\n",
      "domain 4990\n",
      "app_bundle 3570\n",
      "publisher_id 2614\n",
      "device_type 6\n",
      "device_os 11\n",
      "device_os_version 140\n",
      "device_browser 27\n",
      "device_browser_version 893\n",
      "carrier 664\n",
      "language 78\n",
      "exchange_id 7\n",
      "banner_type 3\n",
      "account_campaign 20\n",
      "account_banner 60\n",
      "account_advertiser 8\n",
      "account_offer 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cat_cols = {}\n",
    "column_instance_dict = {}\n",
    "modulos = []\n",
    "for col in tqdm(cat_features):\n",
    "    modulo = df[col].nunique()\n",
    "    cat_cols[col] = modulo\n",
    "    modulos.append(modulo)\n",
    "    column_instance_dict[col] = dict(zip(df[col].unique(), range(len(df[col].unique()))))\n",
    "    df[col] = df[col].map(column_instance_dict[col])\n",
    "for c in cat_features:\n",
    "    print(c, cat_cols[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geo_state': 10,\n",
       " 'geo_country': 5,\n",
       " 'geo_city': 10,\n",
       " 'zip_code': 10,\n",
       " 'category_1': 5,\n",
       " 'domain': 10,\n",
       " 'app_bundle': 10,\n",
       " 'publisher_id': 10,\n",
       " 'device_type': 3,\n",
       " 'device_os': 5,\n",
       " 'device_os_version': 10,\n",
       " 'device_browser': 5,\n",
       " 'device_browser_version': 10,\n",
       " 'carrier': 10,\n",
       " 'language': 5,\n",
       " 'exchange_id': 3,\n",
       " 'banner_type': 3,\n",
       " 'account_campaign': 5,\n",
       " 'account_banner': 5,\n",
       " 'account_advertiser': 3,\n",
       " 'account_offer': 5}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dict = {}\n",
    "for c in cat_cols:\n",
    "    if(cat_cols[c]<=10):\n",
    "        embed_dict[c] = 3\n",
    "    elif(cat_cols[c]<=100):\n",
    "        embed_dict[c] = 5\n",
    "    else:\n",
    "        embed_dict[c] = 10\n",
    "embed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of x columns: 28\n"
     ]
    }
   ],
   "source": [
    "x_cols = [c for c in df.columns if (c != 'clicks') and (c != 'impressions')]\n",
    "print(\"number of x columns: %d\"%(len(x_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_dense: (602733, 7) x_sparse: (602733, 21) y: (602733,) w: (602733,)\n"
     ]
    }
   ],
   "source": [
    "x_sparse = df[x_cols[:len(cat_features)]].values\n",
    "x_dense = df[x_cols[len(cat_features):]].values\n",
    "x = np.concatenate([x_sparse, x_dense], axis=1)\n",
    "y, w = np.array(df[y_col]), np.array(df[w_col])\n",
    "print(\"x_dense: %s x_sparse: %s y: %s w: %s\"%(x_dense.shape, x_sparse.shape, y.shape, w.shape))\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for pytorch and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(x)\n",
    "y = torch.FloatTensor(y)\n",
    "w = torch.FloatTensor(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num obs train 361639\n",
      "num obs val 120547\n",
      "num obs test 120547\n"
     ]
    }
   ],
   "source": [
    "n, m = x.shape\n",
    "randvec = torch.randperm(n)\n",
    "x_train, x_val = torch.split(x[randvec],(n*3)//5, 0)\n",
    "y_train, y_val = torch.split(y[randvec],(n*3)//5, 0)\n",
    "w_train, w_val = torch.split(w[randvec],(n*3)//5, 0)\n",
    "\n",
    "n_val = x_val.shape[0]\n",
    "randvec_val = torch.randperm(n_val)\n",
    "x_val, x_test = torch.split(x_val[randvec_val],n_val//2, 0)\n",
    "y_val, y_test = torch.split(y_val[randvec_val],n_val//2, 0)\n",
    "w_val, w_test = torch.split(w_val[randvec_val],n_val//2, 0)\n",
    "\n",
    "print(\"num obs train %d\\nnum obs val %d\\nnum obs test %d\"%(x_train.shape[0], x_val.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of sparse cols: 21\n",
      "num of dense cols: 7\n"
     ]
    }
   ],
   "source": [
    "m_embed = 10\n",
    "units = 100\n",
    "sparse_col = torch.LongTensor(list(range(0, len(cat_features))))\n",
    "dense_col = torch.LongTensor(list(range(len(cat_features), m)))\n",
    "m_sparse = sparse_col.size()[0]\n",
    "m_dense = dense_col.size()[0]\n",
    "print(\"num of sparse cols: %d\\nnum of dense cols: %d\"%(m_sparse, m_dense))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Network layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "    def forward(self, x, y):\n",
    "        return self.lambd(x, y)\n",
    "    \n",
    "class fullDCN(nn.Module):\n",
    "    def __init__(self, embedding_sizes, num_deep_layers, num_cross_layers):\n",
    "        super().__init__()\n",
    "        self.embedding_layers = nn.ModuleList()\n",
    "        self.num_dls = num_deep_layers\n",
    "        self.num_cls = num_cross_layers\n",
    "        for embed_size in embedding_sizes:\n",
    "            self.embedding_layers.append(nn.Embedding(num_embeddings=embed_size, embedding_dim=m_embed))\n",
    "        cross_layer_size = m_dense+(m_embed*m_sparse)\n",
    "        \n",
    "         #deep network layers\n",
    "        self.fc1 = nn.Linear(cross_layer_size, units, bias=True)\n",
    "        self.fc_bn = nn.BatchNorm1d(units)\n",
    "        self.fc2 = nn.Linear(units, units, bias=True)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        #cross network layers\n",
    "        self.cross_layer = nn.Linear(cross_layer_size, cross_layer_size, bias=True)\n",
    "        self.cross_layer_bn = nn.BatchNorm1d(cross_layer_size)\n",
    "        \n",
    "        #combination layer\n",
    "        self.CombLayer = nn.Linear(units+cross_layer_size, 2, bias=False) \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu0 = nn.ReLU()\n",
    "        \n",
    "        #output\n",
    "        self.output = LambdaLayer(lambda x, y: x / (x + y))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_sparse = x[:,sparse_col].long()\n",
    "        x_dense = x[:,dense_col]\n",
    "        for sparse_feature in range(m_sparse):\n",
    "            new_embed = self.embedding_layers[sparse_feature](x_sparse[:, sparse_feature])\n",
    "            if(sparse_feature==0):\n",
    "                x_embed = new_embed\n",
    "            else:\n",
    "                x_embed = torch.cat([x_embed, new_embed], dim=1)\n",
    "        x0 = torch.cat([x_embed, x_dense], dim=1)\n",
    "        \n",
    "        x_dl = F.relu(self.dropout(self.fc_bn(self.fc1(x0))))\n",
    "        for _ in range(self.num_dls):\n",
    "            x_dl = self.dropout(self.fc_bn(self.fc2(x_dl)))\n",
    "        \n",
    "        x_cl = x0 * self.cross_layer(x0) + x0\n",
    "        for _ in range(1, self.num_cls):\n",
    "            x_cl = x0 * self.cross_layer(x_cl) + x_cl\n",
    "        \n",
    "        x_concat = torch.cat([x_dl, x_cl], dim=1)\n",
    "        x_comb = self.CombLayer(x_concat)\n",
    "        consentration1 = self.relu1(x_comb[:, 0]) + 1.0\n",
    "        consentration0 = self.relu0(x_comb[:, 1]) + 1.0\n",
    "        beta = torch.distributions.Beta(consentration1, consentration0)\n",
    "        print(list(zip(consentration1.data.numpy()[inds], consentration0.data.numpy()[inds])))\n",
    "        return beta.mean, beta.variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fullDCN(\n",
      "  (embedding_layers): ModuleList(\n",
      "    (0): Embedding(642, 10)\n",
      "    (1): Embedding(13, 10)\n",
      "    (2): Embedding(5412, 10)\n",
      "    (3): Embedding(9629, 10)\n",
      "    (4): Embedding(58, 10)\n",
      "    (5): Embedding(4990, 10)\n",
      "    (6): Embedding(3570, 10)\n",
      "    (7): Embedding(2614, 10)\n",
      "    (8): Embedding(6, 10)\n",
      "    (9): Embedding(11, 10)\n",
      "    (10): Embedding(140, 10)\n",
      "    (11): Embedding(27, 10)\n",
      "    (12): Embedding(893, 10)\n",
      "    (13): Embedding(664, 10)\n",
      "    (14): Embedding(78, 10)\n",
      "    (15): Embedding(7, 10)\n",
      "    (16): Embedding(3, 10)\n",
      "    (17): Embedding(20, 10)\n",
      "    (18): Embedding(60, 10)\n",
      "    (19): Embedding(8, 10)\n",
      "    (20): Embedding(11, 10)\n",
      "  )\n",
      "  (fc1): Linear(in_features=217, out_features=100, bias=True)\n",
      "  (fc_bn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (cross_layer): Linear(in_features=217, out_features=217, bias=True)\n",
      "  (cross_layer_bn): BatchNorm1d(217, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (CombLayer): Linear(in_features=317, out_features=2, bias=False)\n",
      "  (relu1): ReLU()\n",
      "  (relu0): ReLU()\n",
      "  (output): LambdaLayer()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "DCNnet = fullDCN(embedding_sizes=modulos, num_deep_layers=10, num_cross_layers=10).to(device)\n",
    "print(DCNnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:\n",
      "criterion:\n",
      "BCELoss()\n",
      "optimizer:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "epochs: 100\n",
      "batch_size: 131072\n",
      "num_batches: 2\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(DCNnet.parameters(), lr=.01, weight_decay=0.01)\n",
    "# optimizer = torch.optim.SGD(DCNnet.parameters(), lr=0.01, momentum=1.2)\n",
    "epochs = 100\n",
    "batch_size = 2**17\n",
    "num_batches = int(len(y_train)//batch_size)\n",
    "print(\"Model parameters:\")\n",
    "print(\"criterion:\\n%s\"%str(criterion))\n",
    "print(\"optimizer:\\n%s\"%str(optimizer))\n",
    "print(\"epochs: %d\"%epochs)\n",
    "print(\"batch_size: %d\"%batch_size)\n",
    "print(\"num_batches: %d\"%num_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "[(7.384731, 1.0), (1.0, 11.224273), (1.0, 41.083767), (15.246966, 16.133774), (1.0, 35.50566), (1.0, 10.479702), (1.0, 14.179443), (1.0, 1.0), (33.121113, 61.21363), (31.378407, 10.507473)]\n",
      "[(1.0, 124.084595), (1.0, 37.319965), (1.0, 157.60117), (1.0, 91.51368), (1.0, 88.88562), (1.0, 570.7906), (1.0, 156.11742), (1.0, 342.62518), (1.0, 79.03148), (1.0, 62.66011)]\n",
      "[11. 14. 14. 22. 13. 14. 11. 28. 12. 15.] \n",
      "\n",
      "e:  1/100, b:  1/ 2, tr_loss=8.640, val_loss=1.072, auc=0.565, cal=5.074, 18.17s\n",
      "[(1.0, 81.09891), (1.0, 55.5766), (1.0, 1.0), (1.0, 50.647568), (1.0, 31.902142), (1.0, 88.77649), (1.0, 197.05617), (1.0, 69.01075), (1.0, 58.184498), (1.0, 38.35004)]\n",
      "[(1.0, 751.497), (1.0, 241.83987), (1.0, 512.72015), (1.0, 197.31166), (1.0, 612.2565), (1.0, 1538.6105), (1.0, 1015.39874), (1.0, 926.97076), (1.0, 257.8253), (1.0, 410.7271)]\n",
      "[11. 14. 14. 22. 13. 14. 11. 28. 12. 15.] \n",
      "\n",
      "e:  1/100, b:  2/ 2, tr_loss=0.480, val_loss=0.846, auc=0.611, cal=0.588, 20.38s\n",
      "[(1.0, 217.323), (1.0, 286.73843), (1.0, 197.35161), (1.0, 276.59003), (1.0, 139.80713), (1.0, 488.036), (1.0, 483.08496), (1.0, 99.78617), (1.0, 223.50168), (1.0, 397.10904)]\n",
      "[(1.0, 1570.0745), (1.0, 634.6779), (1.0, 1093.222), (1.0, 267.05847), (1.0, 1303.6941), (1.0, 2826.4705), (1.0, 2272.751), (1.0, 1719.2257), (1.0, 550.2758), (1.0, 945.5089)]\n",
      "[11. 14. 14. 22. 13. 14. 11. 28. 12. 15.] \n",
      "\n",
      "e:  2/100, b:  1/ 2, tr_loss=0.195, val_loss=0.778, auc=0.659, cal=0.279, 18.92s\n",
      "[(1.0, 925.40967), (1.0, 1350.3289), (1.0, 803.47626), (1.0, 793.594), (1.0, 710.1609), (1.0, 1259.0828), (1.0, 629.1129), (1.0, 860.4103), (1.0, 401.61847), (1.0, 600.6476)]\n",
      "[(1.0, 2404.5623), (1.0, 1165.1409), (1.0, 1814.8364), (1.0, 267.58496), (1.0, 2032.5244), (1.0, 4282.9126), (1.0, 3708.6008), (1.0, 2637.2312), (1.0, 922.22046), (1.0, 1580.2534)]\n",
      "[11. 14. 14. 22. 13. 14. 11. 28. 12. 15.] \n",
      "\n",
      "e:  2/100, b:  2/ 2, tr_loss=0.144, val_loss=0.750, auc=0.716, cal=0.210, 18.73s\n",
      "[(1.0, 508.11804), (1.0, 1023.883), (1.0, 840.11273), (1.0, 1425.944), (1.0, 661.15436), (1.0, 1183.7341), (1.0, 475.477), (1.0, 209.60362), (1.0, 1014.9539), (1.0, 961.58154)]\n",
      "[(1.0, 3154.4487), (1.0, 1743.9509), (1.0, 2547.9075), (1.0, 207.36569), (1.0, 2740.4321), (1.0, 5796.3115), (1.0, 5131.1934), (1.0, 3630.0037), (1.0, 1319.8074), (1.0, 2242.4443)]\n",
      "[11. 14. 14. 22. 13. 14. 11. 28. 12. 15.] \n",
      "\n",
      "e:  3/100, b:  1/ 2, tr_loss=0.121, val_loss=0.735, auc=0.762, cal=0.239, 19.26s\n",
      "[(1.0, 367.045), (1.0, 387.30664), (1.0, 791.52966), (1.0, 1126.1785), (1.0, 1122.635), (1.0, 695.10516), (1.0, 3484.5083), (1.0, 836.2136), (1.0, 1503.2104), (1.0, 3122.9092)]\n",
      "[(1.0, 3767.3013), (1.0, 2294.861), (1.0, 3193.6448), (1.0, 207.67404), (1.0, 3414.851), (1.0, 7216.1396), (1.0, 6494.354), (1.0, 4616.856), (1.0, 1703.4319), (1.0, 2887.52)]\n",
      "[11. 14. 14. 22. 13. 14. 11. 28. 12. 15.] \n",
      "\n",
      "e:  3/100, b:  2/ 2, tr_loss=0.108, val_loss=0.726, auc=0.780, cal=0.283, 19.54s\n",
      "[(1.0, 5048.0015), (1.0, 3439.3286), (1.0, 4058.085), (1.0, 2540.1907), (1.0, 130.09229), (1.0, 323.5504), (1.0, 692.7939), (1.0, 377.3621), (1.0, 570.5342), (1.0, 492.4976)]\n",
      "[(1.0, 4158.0566), (1.0, 2734.21), (1.0, 3680.6663), (1.0, 235.66824), (1.0, 3911.567), (1.0, 8472.289), (1.0, 7519.6826), (1.0, 5529.887), (1.0, 2039.7947), (1.0, 3417.855)]\n",
      "[11. 14. 14. 22. 13. 14. 11. 28. 12. 15.] \n",
      "\n",
      "e:  4/100, b:  1/ 2, tr_loss=0.087, val_loss=0.718, auc=0.786, cal=0.291, 19.26s\n",
      "[(1.0, 1767.1133), (1.0, 1425.3036), (1.0, 218.38007), (1.0, 1225.3103), (1.0, 341.3423), (1.0, 5866.6562), (1.0, 1798.8163), (1.0, 768.1356), (1.0, 1637.8959), (15.119804, 120.74445)]\n",
      "[(1.0, 4297.2764), (1.0, 3030.706), (1.0, 3947.5571), (1.0, 270.71118), (1.0, 4195.6104), (1.0, 9467.739), (1.0, 8098.6973), (1.0, 6298.426), (1.0, 2291.8672), (1.0, 3782.894)]\n",
      "[11. 14. 14. 22. 13. 14. 11. 28. 12. 15.] \n",
      "\n",
      "e:  4/100, b:  2/ 2, tr_loss=0.080, val_loss=0.710, auc=0.788, cal=0.164, 19.20s\n",
      "[(1.0, 364.33643), (1.0, 1844.4271), (1.0, 1576.5438), (1.0, 579.43243), (1.0, 1925.2432), (1.0, 2097.223), (1.0, 1304.4769), (1.0, 1801.3173), (1.0, 370.17383), (1.0, 426.77155)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-47302cd24719>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#Update Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = 0\n",
    "val_loss = 0\n",
    "scale = 10e5\n",
    "mean_val_loss, val_auc, val_cal = [], [], []\n",
    "print(\"start training\")\n",
    "for t in range(epochs):\n",
    "    epochrandvec=torch.randperm(len(y_train))\n",
    "    x_train = x_train[epochrandvec,:]\n",
    "    y_train = y_train[epochrandvec]\n",
    "    w_train = w_train[epochrandvec]\n",
    "    for i in range(num_batches):\n",
    "        start_time = time.time()\n",
    "        indvec = torch.LongTensor(list(range((i)*batch_size, (i)*batch_size+batch_size)))\n",
    "        x_batch = x_train[indvec]\n",
    "        y_batch = y_train[indvec]\n",
    "        criterion.weight = w_train[indvec]\n",
    "        \n",
    "        x_sparse = x_batch[:,sparse_col]\n",
    "        x_dense = x_batch[:,dense_col]\n",
    "\n",
    "        #initialize\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        train_means, trains_variances = DCNnet(x_batch)\n",
    "        loss = criterion(train_means.squeeze(), y_batch)\n",
    "        train_loss = scale*loss.item()\n",
    "#         print(w_train[indvec].data.numpy()[1000:1005])\n",
    "        \n",
    "        #Update Network\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #evaluation metrics\n",
    "        with torch.no_grad():\n",
    "            val_means, val_variances = DCNnet(x_val)\n",
    "            criterion.weight = w_val\n",
    "            print(w_val.data.numpy()[inds], '\\n')\n",
    "            val_loss += scale*criterion(val_means.squeeze(), y_val).item()\n",
    "            mean_val_loss.append(val_loss/((i+1+t*num_batches)*x_val.shape[0]))\n",
    "            val_auc.append(roc_auc_score(y_val.data.numpy(), val_means.data.numpy(), sample_weight=w_val))\n",
    "            val_cal.append((val_means.squeeze().mul(w_val).sum() / y_val.mul(w_val).sum()).item())\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(\"e: %2d/%2d, b: %2d/%2d, tr_loss=%.3f, val_loss=%.3f, auc=%.3f, cal=%.3f, %.2fs\"%\n",
    "              (t+1, epochs, i+1, num_batches, \n",
    "              train_loss/(batch_size*(i+1+t*num_batches)), mean_val_loss[-1], \n",
    "              val_auc[-1], val_cal[-1], elapsed))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 141,  352,  802, 1025, 1066, 1173, 1433, 1554, 1588, 1946])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = list(np.where(w_val>10))[0][:10]\n",
    "inds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate AUC and calibration metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [[x_train, y_train, w_train, 'train'], [x_val, y_val, w_val, 'val'], [x_test, y_test, w_test, 'test']]:\n",
    "    probs = DCNnet(data[0]).squeeze()\n",
    "    sample_weight = data[2].data.numpy()\n",
    "    print(data[3]+':')\n",
    "    print(\"number of observations = %d\"%(len(data[1].data.numpy())))\n",
    "    print(\"\\tAUC = %.4f\"%(roc_auc_score(data[1].data.numpy(), probs.data.numpy(), sample_weight=sample_weight)))\n",
    "    print(\"\\tCalibration = %.4f\"%((probs.mul(data[2]).sum()/data[1].mul(data[2]).sum()).item()))\n",
    "    print(\"\\tctrpm = %.2f\"%(1000*data[1].mul(data[2]).sum()/data[1].mul(data[2]).shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(mean_val_loss, label='validation loss', marker='o')\n",
    "plt.legend()\n",
    "plt.subplot(2,2,2)\n",
    "# plt.plot(probs.data.numpy(), y_val.data.numpy(), 'o')\n",
    "v = torch.cat([probs.reshape((probs.shape[0],1)),y_test.reshape((probs.shape[0],1))], dim=1)\n",
    "v, _ = torch.sort(v, dim=0, descending=True)\n",
    "q = probs.shape[0]//3\n",
    "p_mean = [v[l:(l+q)].mean() for l in range(0, probs.shape[0], q)]\n",
    "y_test_mean = [v[l:(l+q),1].mean() for l in range(0, probs.shape[0], q)]\n",
    "plt.plot(p_mean, y_test_mean, 'og', label='qq: label vs p');\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(val_auc, 'o-', label='auc')\n",
    "plt.legend()\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(val_cal, 'o-', label='calibration')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot, make_dot_from_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.onnx.set_training(model, False):\n",
    "    trace, _ = torch.jit.get_trace_graph(model, args=(x_test,))\n",
    "make_dot_from_trace(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model with onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clipper_admin import ClipperConnection, DockerContainerManager\n",
    "from clipper_admin.deployers.pytorch import deploy_pytorch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18-08-25:15:26:58 INFO     [clipper_admin.py:138] Successfully connected to Clipper cluster at localhost:1337\n",
      "18-08-25:15:26:58 INFO     [deployer_utils.py:44] Saving function to /tmp/clipper/tmp7hyrx534\n",
      "18-08-25:15:26:58 INFO     [deployer_utils.py:54] Serialized and supplied predict function\n",
      "18-08-25:15:26:58 INFO     [pytorch.py:204] Torch model saved\n",
      "18-08-25:15:26:58 INFO     [pytorch.py:217] Using Python 3.6 base image\n",
      "18-08-25:15:26:58 INFO     [clipper_admin.py:452] Building model Docker image with model data from /tmp/clipper/tmp7hyrx534\n"
     ]
    },
    {
     "ename": "ClipperException",
     "evalue": "Error saving torch model: ('Connection aborted.', PermissionError(13, 'Permission denied'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/docker/transport/unixconn.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munix_socket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m                 )\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 638\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/docker/transport/unixconn.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munix_socket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', PermissionError(13, 'Permission denied'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/clipper_admin/deployers/pytorch.py\u001b[0m in \u001b[0;36mdeploy_pytorch_model\u001b[0;34m(clipper_conn, name, version, input_type, func, pytorch_model, base_image, labels, registry, num_replicas, batch_size, pkgs_to_install)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             registry, num_replicas, batch_size, pkgs_to_install)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/clipper_admin/clipper_admin.py\u001b[0m in \u001b[0;36mbuild_and_deploy_model\u001b[0;34m(self, name, version, input_type, model_data_path, base_image, labels, container_registry, num_replicas, batch_size, pkgs_to_install)\u001b[0m\n\u001b[1;32m    335\u001b[0m         image = self.build_model(name, version, model_data_path, base_image,\n\u001b[0;32m--> 336\u001b[0;31m                                  container_registry, pkgs_to_install)\n\u001b[0m\u001b[1;32m    337\u001b[0m         self.deploy_model(name, version, input_type, image, labels,\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/clipper_admin/clipper_admin.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self, name, version, model_data_path, base_image, container_registry, pkgs_to_install)\u001b[0m\n\u001b[1;32m    453\u001b[0m             image_result, build_logs = docker_client.images.build(\n\u001b[0;32m--> 454\u001b[0;31m                 fileobj=context_file, custom_context=True, tag=image)\n\u001b[0m\u001b[1;32m    455\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuild_logs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/docker/models/images.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \"\"\"\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/docker/api/build.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, path, tag, quiet, fileobj, nocache, rm, timeout, custom_context, encoding, pull, forcerm, dockerfile, container_limits, decode, buildargs, gzip, shmsize, labels, cache_from, target, network_mode, squash, extra_hosts, platform, isolation)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         )\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/docker/utils/decorators.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'headers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_general_configs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HttpHeaders'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/docker/api/client.py\u001b[0m in \u001b[0;36m_post\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_request_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'POST'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mProtocolError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: ('Connection aborted.', PermissionError(13, 'Permission denied'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mClipperException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-3939b188fb6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0minput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"doubles\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     pytorch_model=model1)\n\u001b[0m",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/clipper_admin/deployers/pytorch.py\u001b[0m in \u001b[0;36mdeploy_pytorch_model\u001b[0;34m(clipper_conn, name, version, input_type, func, pytorch_model, base_image, labels, registry, num_replicas, batch_size, pkgs_to_install)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mClipperException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error saving torch model: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;31m# Remove temp files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClipperException\u001b[0m: Error saving torch model: ('Connection aborted.', PermissionError(13, 'Permission denied'))"
     ]
    }
   ],
   "source": [
    "clipper_conn = ClipperConnection(DockerContainerManager())\n",
    "\n",
    "# Connect to an already-running Clipper cluster\n",
    "clipper_conn.connect()\n",
    "model1 = nn.Linear(1, 1)\n",
    "\n",
    "# Define a shift function to normalize prediction inputs\n",
    "def predict(model, inputs):\n",
    "    pred = model(shift(inputs))\n",
    "    pred = pred.data.numpy()\n",
    "    return [str(x) for x in pred]\n",
    "\n",
    "deploy_pytorch_model(\n",
    "    clipper_conn,\n",
    "    name=\"example\",\n",
    "    version=1,\n",
    "    input_type=\"doubles\",\n",
    "    func=predict,\n",
    "    pytorch_model=model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "/pytorch/torch/csrc/jit/tracer.h:143: getTracingState: Assertion `var_state == state` failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-3200144b904b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# writer = SummaryWriter(comment='testing')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# writer.add_graph(DCNnet, , verbose=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0m_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDCNnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dcnet.onnx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, propagate)\u001b[0m\n\u001b[1;32m    224\u001b[0m                                                \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                                                \u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator_export_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                                                example_outputs, propagate)\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m# TODO: Don't allocate a in-memory string for the protobuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, f, verbose, training, input_names, output_names, operator_export_type, example_outputs, propagate)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\'forward\\' method must be a script method'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_trace_and_get_graph_from_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args, training)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;31m# training mode was.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mset_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0morig_state_dict_keys\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mget_trace_graph\u001b[0;34m(f, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mLegacyTracedModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0minput_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0mtracing_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtracing_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/env_python36/lib64/python3.6/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mget_tracing_state\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: /pytorch/torch/csrc/jit/tracer.h:143: getTracingState: Assertion `var_state == state` failed."
     ]
    }
   ],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "from torch.onnx import export, _export\n",
    "\n",
    "# writer = SummaryWriter(comment='testing')\n",
    "# writer.add_graph(DCNnet, , verbose=False)\n",
    "_export(DCNnet, x_test, 'dcnet.onnx', verbose=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fullDCN(\n",
      "  (embedding_layers): ModuleList(\n",
      "    (0): Embedding(642, 10)\n",
      "    (1): Embedding(13, 10)\n",
      "    (2): Embedding(5412, 10)\n",
      "    (3): Embedding(9629, 10)\n",
      "    (4): Embedding(58, 10)\n",
      "    (5): Embedding(4990, 10)\n",
      "    (6): Embedding(3570, 10)\n",
      "    (7): Embedding(2614, 10)\n",
      "    (8): Embedding(6, 10)\n",
      "    (9): Embedding(11, 10)\n",
      "    (10): Embedding(140, 10)\n",
      "    (11): Embedding(27, 10)\n",
      "    (12): Embedding(893, 10)\n",
      "    (13): Embedding(664, 10)\n",
      "    (14): Embedding(78, 10)\n",
      "    (15): Embedding(7, 10)\n",
      "    (16): Embedding(3, 10)\n",
      "    (17): Embedding(20, 10)\n",
      "    (18): Embedding(60, 10)\n",
      "    (19): Embedding(8, 10)\n",
      "    (20): Embedding(11, 10)\n",
      "  )\n",
      "  (fc1): Linear(in_features=217, out_features=100, bias=True)\n",
      "  (fc_bn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (cross_layer): Linear(in_features=217, out_features=217, bias=True)\n",
      "  (cross_layer_bn): BatchNorm1d(217, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (CombLayer): Linear(in_features=317, out_features=2, bias=False)\n",
      "  (relu1): ReLU()\n",
      "  (relu0): ReLU()\n",
      "  (output): LambdaLayer()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(DCNnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
